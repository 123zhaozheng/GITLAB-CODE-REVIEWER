#!/usr/bin/env python3
"""
å¿«é€Ÿå†…æµ‹è„šæœ¬ - ä¸€é”®è¿è¡Œæ‰€æœ‰æµ‹è¯•åœºæ™¯
"""
import asyncio
import aiohttp
import json
import time
import sys
from typing import Dict, Any

class QuickTester:
    """å¿«é€Ÿå†…æµ‹å·¥å…·"""
    
    def __init__(self, api_url: str = "http://localhost:8001"):
        self.api_url = api_url.rstrip('/')
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            async with self.session.get(f"{self.api_url}/health") as resp:
                if resp.status == 200:
                    data = await resp.json()
                    print(f"âœ… æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡: {data['status']}")
                    return True
                else:
                    print(f"âŒ æœåŠ¡å¼‚å¸¸: HTTP {resp.status}")
                    return False
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡: {e}")
            return False
    
    async def test_single_review(self, scenario: str = "default") -> Dict[str, Any]:
        """æµ‹è¯•å•ä¸ªå®¡æŸ¥åœºæ™¯"""
        print(f"\nğŸ” æµ‹è¯•åœºæ™¯: {scenario}")
        
        payload = {
            "project_id": "123",
            "mr_id": 456,
            "review_type": "full",
            "mock_scenario": scenario
        }
        
        start_time = time.time()
        
        try:
            async with self.session.post(
                f"{self.api_url}/test/review",
                json=payload
            ) as resp:
                if resp.status == 200:
                    result = await resp.json()
                    duration = time.time() - start_time
                    
                    print(f"  âœ… å®¡æŸ¥å®Œæˆ ({duration:.2f}ç§’)")
                    print(f"  ğŸ“Š è¯„åˆ†: {result['score']}/10.0")
                    print(f"  ğŸ” å‘ç°é—®é¢˜: {len(result.get('findings', []))}ä¸ª")
                    print(f"  ğŸ“ åˆ†ææ–‡ä»¶: {result.get('statistics', {}).get('files_analyzed', 0)}ä¸ª")
                    
                    return result
                else:
                    error = await resp.text()
                    print(f"  âŒ å®¡æŸ¥å¤±è´¥: {error}")
                    return None
                    
        except Exception as e:
            print(f"  âŒ è¯·æ±‚å¼‚å¸¸: {e}")
            return None
    
    async def test_all_scenarios(self):
        """æµ‹è¯•æ‰€æœ‰åœºæ™¯"""
        print("\nğŸ“‹ è·å–å¯ç”¨åœºæ™¯...")
        
        try:
            async with self.session.get(f"{self.api_url}/test/scenarios") as resp:
                scenarios_data = await resp.json()
                scenarios = list(scenarios_data["scenarios"].keys())
                
                print(f"å‘ç° {len(scenarios)} ä¸ªæµ‹è¯•åœºæ™¯")
                
                results = []
                for scenario in scenarios:
                    result = await self.test_single_review(scenario)
                    if result:
                        results.append({
                            "scenario": scenario,
                            "score": result["score"],
                            "findings": len(result.get("findings", []))
                        })
                
                print(f"\nğŸ“Š åœºæ™¯æµ‹è¯•æ±‡æ€»:")
                for result in results:
                    print(f"  {result['scenario']}: {result['score']}/10.0 ({result['findings']}ä¸ªé—®é¢˜)")
                
                return results
                
        except Exception as e:
            print(f"âŒ è·å–åœºæ™¯å¤±è´¥: {e}")
            return []
    
    async def test_performance(self):
        """æ€§èƒ½æµ‹è¯•"""
        print(f"\nâš¡ æ‰§è¡Œæ€§èƒ½æµ‹è¯•...")
        
        try:
            async with self.session.post(f"{self.api_url}/test/performance") as resp:
                if resp.status == 200:
                    result = await resp.json()
                    perf = result["performance_test"]
                    
                    print(f"  ğŸ“ˆ å¹¶å‘è¯·æ±‚: {perf['concurrent_requests']}")
                    print(f"  â±ï¸ æ€»è€—æ—¶: {perf['total_time']}ç§’")
                    print(f"  ğŸš€ å¹³å‡å“åº”æ—¶é—´: {perf['average_time_per_request']}ç§’")
                    print(f"  âœ… æˆåŠŸç‡: {perf['success_rate']}")
                    
                    if perf.get('errors'):
                        print(f"  âŒ é”™è¯¯: {len(perf['errors'])}ä¸ª")
                    
                    return result
                else:
                    error = await resp.text()
                    print(f"  âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {error}")
                    
        except Exception as e:
            print(f"âŒ æ€§èƒ½æµ‹è¯•å¼‚å¸¸: {e}")
    
    async def test_ai_models(self):
        """æµ‹è¯•AIæ¨¡å‹"""
        print(f"\nğŸ¤– æµ‹è¯•AIæ¨¡å‹è¿æ¥...")
        
        try:
            async with self.session.get(f"{self.api_url}/test/ai-models") as resp:
                if resp.status == 200:
                    result = await resp.json()
                    
                    print(f"  ğŸ“¡ çŠ¶æ€: {result['status']}")
                    print(f"  ğŸ§  æ¨¡å‹: {result['model']}")
                    
                    if result['status'] == 'available':
                        print(f"  âœ… AIæ¨¡å‹è¿æ¥æ­£å¸¸")
                    else:
                        print(f"  âŒ AIæ¨¡å‹è¿æ¥å¼‚å¸¸: {result.get('error', 'Unknown')}")
                    
                    return result
                    
        except Exception as e:
            print(f"âŒ AIæ¨¡å‹æµ‹è¯•å¼‚å¸¸: {e}")
    
    async def test_batch_review(self):
        """æ‰¹é‡æµ‹è¯•"""
        print(f"\nğŸ“¦ æ‰§è¡Œæ‰¹é‡æµ‹è¯•...")
        
        try:
            async with self.session.post(f"{self.api_url}/test/batch-review") as resp:
                if resp.status == 200:
                    result = await resp.json()
                    summary = result["summary"]
                    
                    print(f"  ğŸ“Š æ€»æ•°: {summary['total']}")
                    print(f"  âœ… æˆåŠŸ: {summary['success']}")
                    print(f"  âŒ å¤±è´¥: {summary['failed']}")
                    
                    print(f"\n  è¯¦ç»†ç»“æœ:")
                    for test_result in result["batch_test_results"]:
                        if test_result.get("status") == "success":
                            print(f"    âœ… {test_result['scenario']}: {test_result['score']}/10.0")
                        else:
                            print(f"    âŒ {test_result['scenario']}: {test_result.get('error', 'Unknown error')}")
                    
                    return result
                    
        except Exception as e:
            print(f"âŒ æ‰¹é‡æµ‹è¯•å¼‚å¸¸: {e}")
    
    async def run_full_test(self):
        """è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶"""
        print("ğŸš€ GitLab Code Reviewer å¿«é€Ÿå†…æµ‹")
        print("=" * 50)
        
        # 1. å¥åº·æ£€æŸ¥
        if not await self.health_check():
            print("âŒ æœåŠ¡æœªå¯åŠ¨ï¼Œè¯·å…ˆè¿è¡Œ: python test_api.py")
            return False
        
        # 2. AIæ¨¡å‹æµ‹è¯•
        await self.test_ai_models()
        
        # 3. å•ä¸ªåœºæ™¯æµ‹è¯•
        await self.test_single_review("default")
        
        # 4. æ€§èƒ½æµ‹è¯•
        await self.test_performance()
        
        # 5. æ‰¹é‡æµ‹è¯•
        await self.test_batch_review()
        
        # 6. æ‰€æœ‰åœºæ™¯æµ‹è¯•
        await self.test_all_scenarios()
        
        print("\n" + "=" * 50)
        print("ğŸ‰ å†…æµ‹å®Œæˆï¼")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("  1. è®¿é—® http://localhost:8001/docs æŸ¥çœ‹APIæ–‡æ¡£")
        print("  2. ä¿®æ”¹é…ç½®åæµ‹è¯•çœŸå®GitLabé›†æˆ")
        print("  3. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ")
        
        return True

async def main():
    """ä¸»å‡½æ•°"""
    print("GitLab Code Reviewer å¿«é€Ÿå†…æµ‹å·¥å…·")
    
    # æ£€æŸ¥å‚æ•°
    if len(sys.argv) > 1:
        if sys.argv[1] == "--scenario":
            scenario = sys.argv[2] if len(sys.argv) > 2 else "default"
            async with QuickTester() as tester:
                await tester.test_single_review(scenario)
            return
        elif sys.argv[1] == "--performance":
            async with QuickTester() as tester:
                await tester.test_performance()
            return
        elif sys.argv[1] == "--ai":
            async with QuickTester() as tester:
                await tester.test_ai_models()
            return
    
    # è¿è¡Œå®Œæ•´æµ‹è¯•
    async with QuickTester() as tester:
        await tester.run_full_test()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ æµ‹è¯•ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        sys.exit(1)